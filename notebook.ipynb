{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM Tutorial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<table class=\"nt-notebook-buttons\" align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/JeremieGince/Learning_SVM/blob/main/notebook.ipynb\"><img src=\"https://github.com/NeuroTorch/NeuroTorch/blob/main/images/colab_logo_32px.png?raw=true\" width=32px height=32px  />Run in Google Colab</a>\n",
    "</td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/JeremieGince/Learning_SVM/blob/main/notebook.ipynb\"><img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\" width=32px height=32px />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/JeremieGince/Learning_SVM/blob/main/notebook.ipynb\"><img src=\"https://github.com/NeuroTorch/NeuroTorch/blob/main/images/download_logo_32px.png?raw=true\" width=32px height=32px />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can now install the dependencies by running the following commands:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "#@title Install dependencies {display-mode: \"form\"}\n",
    "\n",
    "RunningInCOLAB = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    !git clone https://github.com/JeremieGince/Learning_SVM.git\n",
    "    %cd Learning_SVM/\n",
    "\n",
    "!pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After setting up the virtual environment, we will need to import the necessary packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "if RunningInCOLAB:\n",
    "    from Learning_SVM.kernels import ClassicalKernel, QuantumKernel\n",
    "    from Learning_SVM.scratch import SVC\n",
    "    from Learning_SVM.visualization import Visualizer\n",
    "else:\n",
    "    from kernels import ClassicalKernel, QuantumKernel\n",
    "    from scratch import SVMFromScratch\n",
    "    from visualization import Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "In the next cell, we will load the dataset. By uncommenting the appropriate line, you can choose between the breast cancer, iris, or synthetic dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dataset = datasets.load_breast_cancer(as_frame=True)\n",
    "# dataset = datasets.load_iris(as_frame=True)\n",
    "dataset = datasets.make_classification(\n",
    "    n_samples=100,\n",
    "    n_features=4,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=1,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    random_state=0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if isinstance(dataset, tuple):\n",
    "    X, y = dataset\n",
    "elif isinstance(dataset, dict):\n",
    "    X = dataset[\"data\"]\n",
    "    y = dataset[\"target\"]\n",
    "elif isinstance(dataset, pd.DataFrame):\n",
    "    X = dataset.data\n",
    "    y = dataset.target\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset type: {type(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X = StandardScaler().fit_transform(X)\n",
    "X = MinMaxScaler(feature_range=(0, 1)).fit_transform(X)\n",
    "# y = MinMaxScaler(feature_range=(-1, 1)).fit_transform(y.reshape(-1, 1)).reshape(-1).astype(int)\n",
    "print(f\"{X.shape = }, {y.shape = }\")\n",
    "print(f\"{np.unique(y) = }\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedding_size = X.shape[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kernel\n",
    "\n",
    "Here we will use a classical and a quantum kernel to train the SVM models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clas_kernel = ClassicalKernel(\n",
    "    embedding_dim=embedding_size,\n",
    "    metric=\"rbf\",\n",
    "    seed=0\n",
    ").fit(X, y)\n",
    "\n",
    "q_kernel = QuantumKernel(\n",
    "    embedding_dim=embedding_size,\n",
    "    seed=0,\n",
    "    # encoder_matrix=rn_embed_matrix,\n",
    "    shots=128,\n",
    "    nb_workers=max(0, psutil.cpu_count(logical=False) - 2),\n",
    "    interface=\"auto\",\n",
    ").fit(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVM\n",
    "\n",
    "We will use the classical and quantum kernels to train the SVM models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clas_model = svm.SVC(kernel=clas_kernel.kernel, random_state=0)\n",
    "qml_model = svm.SVC(kernel=q_kernel.kernel, random_state=0)\n",
    "scratch_model = SVC(kernel=clas_kernel.kernel, max_iter=1_000)\n",
    "q_scratch_model = SVC(kernel=q_kernel.kernel, max_iter=1_000)\n",
    "\n",
    "models = {\n",
    "    \"classical\": clas_model,\n",
    "    \"scratch\": scratch_model,\n",
    "    \"qml\": qml_model,\n",
    "    \"q_scratch\": q_scratch_model,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training & Evaluation\n",
    "\n",
    "We will now train the models and evaluate their performance. We will also visualize the decision boundaries in the reduced space."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_plots = len(models)\n",
    "n_rows = int(np.ceil(np.sqrt(n_plots)))\n",
    "n_cols = int(np.ceil(n_plots / n_rows))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, tight_layout=True, figsize=(14, 10), sharex=\"all\", sharey=\"all\")\n",
    "axes = np.ravel(np.asarray([axes]))\n",
    "for i, (m_name, model) in enumerate(models.items()):\n",
    "    fit_start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    fit_end_time = time.time()\n",
    "    fit_time = fit_end_time - fit_start_time\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    print(f\"{m_name} test accuracy: {accuracy * 100 :.4f}%, {fit_time = :.5f} [s]\")\n",
    "\n",
    "    fig, ax = Visualizer.plot_2d_decision_boundaries(\n",
    "        model=model,\n",
    "        X=X, y=y,\n",
    "        # reducer=decomposition.PCA(n_components=2, random_state=0),\n",
    "        # reducer=umap.UMAP(n_components=2, transform_seed=0, n_jobs=max(0, psutil.cpu_count() - 2)),\n",
    "        check_estimators=False,\n",
    "        n_pts=(1_000 if m_name.startswith('q') else 100_000),\n",
    "        title=f\"Decision boundaries in the reduced space.\",\n",
    "        legend_labels=getattr(dataset, \"target_names\", None),\n",
    "        # axis_name=\"RN\",\n",
    "        fig=fig, ax=axes[i],\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    ax.set_title(f\"{m_name} accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
